---
layout: post
title: 笔记-吴恩达deeplearning之六
comments: true
date: 2017-09-28 16:59:56
tags:
- 笔记
- 深度学习
---
假设经过了一段时间的调整，使得分类器准确率达到了90%，
但对于应用程序来说还是不够好，所以系统还需改善，

比如收集更多的训练数据，或许训练集多样性还不够，
或者需要更多的反例集，或者梯度下降训练算法可以训练久一点，
或者尝试一个不同的优化算法，尝试更大规模的神经网络。
<!--more-->
但是问题在于，如果一旦做出了错误的选择，完全有可能，
直到很久之后才知道此路不通，那将浪费大量的时间。

搭建机器学习的挑战是，可尝试的东西太多了

# 正交化
![](/assets/images/170928.JPG)
例如老式电视，上面有很多旋钮来调整图像的各种性质，
如果有一个按钮可以同时调整图像高度、宽度、角度之类的，
那这台电视将几乎不可能被调好，让图像显示在区域中间。

这种情况下，正交化指电视设计师保证每个按钮只调整一个性质，
这样调整电视图像将容易得多。

弄好一个监督学习系统，通长需要调节系统，需要确保四件事：
1. 系统在训练集上得到的结果不错
2. 系统在开发集上有好的表现
3. 系统在测试集上也有好的表现
4. 系统在测试集上成本函数令人满意

如果发现算法对训练集做的很好，但开发集的拟合很差，
则需要一组正则化旋钮可以调节，使系统满足第二个条件。

如果此时不符合第三个标准，可能调节更大的开发集。
如果第四个条件不符合，这意味着需要改变开发集或成本函数。

# 单一数字评估指标

单一数字评估指标可以帮你加快进展，
它会告诉你，尝试的新方法比之前的方法好还是不好，
当团队开始进行机器学习项目时，可以为问题设置一个单实数评估指标，

应用机器学习是一个非常经验性的过程，用实验结果来改善想法，
然后继续实验，循环，不断地改进算法。

比如图片分类器，搭建的分类器A，通过改变超参数、训练集等手段，
现在训练出一个新的分类器B，所以评估一个分类器的合理方式是，
观察它的查准率和查全率。

但使用查准率和查全率作为指标时，如果分类器A在查全率上表现更好，
分类器B在查准率上表现更好，那就无法判断哪个分类器更好了。
所以不推荐使用两个评估标准来选择一个分类器。

在文献中，结合查准率和查全率的标准方法是所谓F1分数，
非正式的可认为是查准率P和查全率R的调和平均值，
这个指标在权衡查准率和查全率时很有优势。

# 满足和优化指标

要把顾及到的所有事，组成单实数评估指标并不容易，
那么还可以设置满足和优化指标。

假设看重分类器的准确度，但除了准确度，还需考虑运行时间，
那么可以将准确度和运行时间组成一个整体评估指标，
比如总成本是准确度减去0.5倍运行时间，

也可以选择一个分类器，在满足运行时间下，尽可能降低准确度，
在这种情况下，准确度可以是一个优化指标，
因为此时只追求准确度的最大化，运行时间达到要求后就无所谓了，
这也是一种合理的权衡方式，或者说将准确度和运行时间结合起来的方式。

通过定义优化和满足指标，可以提供一个明确的方式去选择最好的分类器，

# 训练/开发/测试集划分

设立训练集、开发集和测试集的方式，将会大大影响你或你的团队，
在机器学习方面取得进展的速度。

机器学习的工作流程是，尝试多种思路，用训练集训练不同的模型，
然后使用开发集来评估不同的思路，然后选择其中一个，
然后不断地迭代去改善开发集的性能，直到最后得到一个满意的成本，
再用测试集去评估。

建议：
开发集和测试集来自同一分布；
选择能反映未来会得到的数据的开发集和测试集，

在深度学习时代，设立开发集和测试集的方针也在变化，

在机器学习早期中，将取得的全部数据按7:3的比例分成训练集和测试集，
这样分在数据集很小的时候，是相当合理的，
但在现代机器学习中，我们可以轻易获得规模很大的数据集，
或许将98%作为训练集，1%作为开发集，1%作为测试集更为合理。

测试集的目的是完成系统后，评估投产系统的性能，
策略就是令训练集足够大，能够高置信度评估系统整体性能，
故除非对最终投产系统有很精确的指标，一般来说测试集不需要很大。

项目进行中，可能会发现目标放错了，这种情况下，应该移动目标。
例如构建一个图片分类器，试图找到很多目标图片，使用的指标为分类误差，
算法A和B分别有3%和5%的误差，似乎算法A做的更好，但实际测试时，
算法A由于某些问题，把很多无关的图片分错类了，
如果部署算法A，那么用户看到更多目标图片，因为误差小，但它也会给用户推送一些不能接受的无关图片，
相比之下算法B虽然得到较少的目标图像，但不会推送无关图像，从用户角度，算法B实际上更好一点，
这个例子中算法A评估指标做得好，但实际是个糟糕的算法。

这种情况发生时，当评估指标无法正确衡量算法之间的优劣时，就需要改变评估指标了，或者改变开发集或测试集。

让一个监督学习算法达到实用，基本上希望可以完成两件事，
首先，算法对训练集的拟合很好，即可避免偏差很低，
然后，做到训练集很好，开发集和测试集也很好，即方差不是太大，

想提升机器学习系统的性能，建议看看训练误差和贝叶斯误差估计值间的距离，明白偏差有多大，
然后看开发误差和训练误差间距离，明白方差问题有多大。

# 误差分析

假设正在调整分类器，取得90%的准确率，相当于10%的误差，
在开发集上还未达到目标，经检查，算法将狗误判为猫了，
建议针对狗的算法进行优化，那么是否需要建立针对狗的算法？
通过误差分析流程，可以尽快知道该方向是否值得行动。

例如：
首先收集错误标记的开发集例子，
然后手动检查多少例子是狗，
如果狗的例子很少，那么就无需在狗上耗费太多精力。

如果正在开发新的机器学习应用，
应该快速设立开发集和测试集还有指标，
然后尽快建立第一个机器学习系统原型，
然后使用偏差方差分析、误差分析来确定下一步方向。